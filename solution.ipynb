{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c0cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UCI HAR Dataset - RAW INERTIAL SIGNALS...\n",
      "Loading training raw signals...\n",
      "Loading test raw signals...\n",
      " Raw signals loaded successfully:\n",
      "   Training raw: (7352, 128, 9) (samples, timesteps, sensors)\n",
      "   Test raw: (2947, 128, 9)\n",
      "   Training flat: (7352, 1152) (for MLP)\n",
      "   Test flat: (2947, 1152) (for MLP)\n",
      "   Labels: (7352,) train, (2947,) test\n",
      "\n",
      " Starting comprehensive benchmarking with RAW signals...\n",
      "\n",
      " Training MLP...\n",
      "Building MLP model...\n",
      "Architecture: Input → Dense(512) → Dense(256) → Dense(128) → Output\n",
      "MLP model built with 755,334 parameters\n",
      "\n",
      "============================================================\n",
      "Training MLP\n",
      "============================================================\n",
      "Using flattened signals shape: (7352, 1152)\n",
      "Epoch 1/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6533 - loss: 0.9595 - val_accuracy: 0.8926 - val_loss: 0.4118\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.5118 - val_accuracy: 0.9157 - val_loss: 0.3257\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3483 - val_accuracy: 0.9245 - val_loss: 0.2759\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2997 - val_accuracy: 0.9239 - val_loss: 0.2855\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2562 - val_accuracy: 0.9307 - val_loss: 0.3256\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.2170 - val_accuracy: 0.9252 - val_loss: 0.3028\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2043 - val_accuracy: 0.9211 - val_loss: 0.3079\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2024 - val_accuracy: 0.9266 - val_loss: 0.2506\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.1816 - val_accuracy: 0.9205 - val_loss: 0.3076\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.1721 - val_accuracy: 0.9259 - val_loss: 0.3154\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.1589 - val_accuracy: 0.9293 - val_loss: 0.3431\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1536 - val_accuracy: 0.9327 - val_loss: 0.3443\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9288 - loss: 0.1779 - val_accuracy: 0.9347 - val_loss: 0.2998\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.1561 - val_accuracy: 0.9300 - val_loss: 0.3784\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1346 - val_accuracy: 0.9205 - val_loss: 0.3330\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1647 - val_accuracy: 0.9293 - val_loss: 0.3179\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.1627 - val_accuracy: 0.9177 - val_loss: 0.3035\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1350 - val_accuracy: 0.9130 - val_loss: 0.3414\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1368 - val_accuracy: 0.9225 - val_loss: 0.3245\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1218 - val_accuracy: 0.9293 - val_loss: 0.3890\n",
      "\n",
      "MLP Results:\n",
      "Accuracy:  0.9169\n",
      "Precision: 0.9184\n",
      "Recall:    0.9193\n",
      "F1-Score:  0.9172\n",
      "\n",
      "Detailed Classification Report for MLP:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.99      0.93      0.96       496\n",
      "  WALKING_UPSTAIRS       0.93      0.96      0.94       471\n",
      "WALKING_DOWNSTAIRS       0.91      0.98      0.94       420\n",
      "           SITTING       0.78      0.87      0.82       491\n",
      "          STANDING       0.91      0.78      0.84       532\n",
      "            LAYING       0.99      1.00      1.00       537\n",
      "\n",
      "          accuracy                           0.92      2947\n",
      "         macro avg       0.92      0.92      0.92      2947\n",
      "      weighted avg       0.92      0.92      0.92      2947\n",
      "\n",
      "\n",
      " Training CNN...\n",
      "Building CNN model...\n",
      "Architecture: Input → Conv1D → Conv1D → GlobalMaxPool → Dense → Output\n",
      "CNN model built with 105,414 parameters\n",
      "\n",
      "============================================================\n",
      "Training CNN\n",
      "============================================================\n",
      "Using raw signals shape: (7352, 128, 9)\n",
      "Epoch 1/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7915 - loss: 0.5382 - val_accuracy: 0.9001 - val_loss: 0.2725\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9390 - loss: 0.1631 - val_accuracy: 0.9171 - val_loss: 0.2390\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9452 - loss: 0.1364 - val_accuracy: 0.8960 - val_loss: 0.2834\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9502 - loss: 0.1252 - val_accuracy: 0.9014 - val_loss: 0.2734\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9527 - loss: 0.1150 - val_accuracy: 0.9123 - val_loss: 0.2578\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9554 - loss: 0.0951 - val_accuracy: 0.9007 - val_loss: 0.2822\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9585 - loss: 0.0887 - val_accuracy: 0.8987 - val_loss: 0.3397\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.0933 - val_accuracy: 0.9123 - val_loss: 0.2914\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9592 - loss: 0.0835 - val_accuracy: 0.8899 - val_loss: 0.3067\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9486 - loss: 0.1265 - val_accuracy: 0.9069 - val_loss: 0.2976\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9575 - loss: 0.0917 - val_accuracy: 0.8973 - val_loss: 0.3248\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9577 - loss: 0.0831 - val_accuracy: 0.8885 - val_loss: 0.3373\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9633 - loss: 0.0756 - val_accuracy: 0.9143 - val_loss: 0.3573\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9612 - loss: 0.0803 - val_accuracy: 0.9048 - val_loss: 0.3580\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9634 - loss: 0.0736 - val_accuracy: 0.9116 - val_loss: 0.4413\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.0824 - val_accuracy: 0.9055 - val_loss: 0.4009\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9604 - loss: 0.0797 - val_accuracy: 0.9137 - val_loss: 0.4238\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9626 - loss: 0.0780 - val_accuracy: 0.8967 - val_loss: 0.3420\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9645 - loss: 0.0702 - val_accuracy: 0.8865 - val_loss: 0.4409\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9607 - loss: 0.0782 - val_accuracy: 0.9150 - val_loss: 0.3592\n",
      "\n",
      "CNN Results:\n",
      "Accuracy:  0.9199\n",
      "Precision: 0.9217\n",
      "Recall:    0.9224\n",
      "F1-Score:  0.9205\n",
      "\n",
      "Detailed Classification Report for CNN:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.99      0.93      0.96       496\n",
      "  WALKING_UPSTAIRS       0.98      0.94      0.96       471\n",
      "WALKING_DOWNSTAIRS       0.88      0.99      0.93       420\n",
      "           SITTING       0.80      0.88      0.84       491\n",
      "          STANDING       0.89      0.79      0.84       532\n",
      "            LAYING       0.99      1.00      0.99       537\n",
      "\n",
      "          accuracy                           0.92      2947\n",
      "         macro avg       0.92      0.92      0.92      2947\n",
      "      weighted avg       0.92      0.92      0.92      2947\n",
      "\n",
      "\n",
      " Training LSTM...\n",
      "Building LSTM model...\n",
      "Architecture: Input → LSTM(100) → LSTM(100) → Dense(50) → Output\n",
      "LSTM model built with 129,756 parameters\n",
      "\n",
      "============================================================\n",
      "Training LSTM\n",
      "============================================================\n",
      "Using raw signals shape: (7352, 128, 9)\n",
      "Epoch 1/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4174 - loss: 1.3583 - val_accuracy: 0.6186 - val_loss: 1.0173\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.5587 - loss: 1.0080 - val_accuracy: 0.6873 - val_loss: 0.7999\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.6307 - loss: 0.8457 - val_accuracy: 0.7763 - val_loss: 0.6845\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.6664 - loss: 0.7700 - val_accuracy: 0.7845 - val_loss: 0.7211\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7048 - loss: 0.6897 - val_accuracy: 0.8165 - val_loss: 0.6108\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.7489 - loss: 0.6273 - val_accuracy: 0.8552 - val_loss: 0.5044\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7771 - loss: 0.5879 - val_accuracy: 0.8736 - val_loss: 0.4566\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.8141 - loss: 0.5100 - val_accuracy: 0.8987 - val_loss: 0.3383\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.8312 - loss: 0.4520 - val_accuracy: 0.8980 - val_loss: 0.3565\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.8476 - loss: 0.4275 - val_accuracy: 0.9014 - val_loss: 0.3405\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.8619 - loss: 0.3699 - val_accuracy: 0.8987 - val_loss: 0.4230\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.8718 - loss: 0.3608 - val_accuracy: 0.8987 - val_loss: 0.3785\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.8735 - loss: 0.3294 - val_accuracy: 0.9089 - val_loss: 0.3569\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.8781 - loss: 0.3241 - val_accuracy: 0.9048 - val_loss: 0.3090\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.8684 - loss: 0.3791 - val_accuracy: 0.9103 - val_loss: 0.3540\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.8930 - loss: 0.2941 - val_accuracy: 0.9123 - val_loss: 0.3739\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.8966 - loss: 0.2714 - val_accuracy: 0.9021 - val_loss: 0.3566\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9063 - loss: 0.2516 - val_accuracy: 0.9021 - val_loss: 0.2958\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.8980 - loss: 0.2730 - val_accuracy: 0.8987 - val_loss: 0.3137\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.8905 - loss: 0.3099 - val_accuracy: 0.9001 - val_loss: 0.2750\n",
      "\n",
      "LSTM Results:\n",
      "Accuracy:  0.9084\n",
      "Precision: 0.9117\n",
      "Recall:    0.9098\n",
      "F1-Score:  0.9089\n",
      "\n",
      "Detailed Classification Report for LSTM:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.97      0.92      0.94       496\n",
      "  WALKING_UPSTAIRS       0.99      0.94      0.97       471\n",
      "WALKING_DOWNSTAIRS       0.89      1.00      0.94       420\n",
      "           SITTING       0.85      0.74      0.79       491\n",
      "          STANDING       0.78      0.87      0.82       532\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "\n",
      "          accuracy                           0.91      2947\n",
      "         macro avg       0.91      0.91      0.91      2947\n",
      "      weighted avg       0.91      0.91      0.91      2947\n",
      "\n",
      "\n",
      " Training CNN-LSTM...\n",
      "Building CNN-LSTM Hybrid model...\n",
      "Architecture: Input → Conv1D → Conv1D → MaxPool → LSTM → LSTM → Dense → Output\n",
      "CNN-LSTM model built with 60,200 parameters\n",
      "\n",
      "============================================================\n",
      "Training CNN-LSTM\n",
      "============================================================\n",
      "Using raw signals shape: (7352, 128, 9)\n",
      "Epoch 1/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.4929 - loss: 1.0832 - val_accuracy: 0.6003 - val_loss: 0.8194\n",
      "Epoch 2/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6178 - loss: 0.7598 - val_accuracy: 0.6139 - val_loss: 0.8108\n",
      "Epoch 3/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6562 - loss: 0.6957 - val_accuracy: 0.6166 - val_loss: 0.8696\n",
      "Epoch 4/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6910 - loss: 0.6165 - val_accuracy: 0.7124 - val_loss: 0.8211\n",
      "Epoch 5/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7684 - loss: 0.5195 - val_accuracy: 0.7315 - val_loss: 0.7092\n",
      "Epoch 6/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8124 - loss: 0.4291 - val_accuracy: 0.7627 - val_loss: 0.7284\n",
      "Epoch 7/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8483 - loss: 0.3585 - val_accuracy: 0.7614 - val_loss: 0.6974\n",
      "Epoch 8/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8653 - loss: 0.3393 - val_accuracy: 0.8933 - val_loss: 0.5669\n",
      "Epoch 9/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9058 - loss: 0.2568 - val_accuracy: 0.9205 - val_loss: 0.2712\n",
      "Epoch 10/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9255 - loss: 0.2206 - val_accuracy: 0.9191 - val_loss: 0.3148\n",
      "Epoch 11/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9395 - loss: 0.1654 - val_accuracy: 0.9055 - val_loss: 0.3884\n",
      "Epoch 12/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9447 - loss: 0.1582 - val_accuracy: 0.8994 - val_loss: 0.4323\n",
      "Epoch 13/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9495 - loss: 0.1284 - val_accuracy: 0.9062 - val_loss: 0.4655\n",
      "Epoch 14/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9458 - loss: 0.1354 - val_accuracy: 0.9075 - val_loss: 0.4513\n",
      "Epoch 15/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9492 - loss: 0.1254 - val_accuracy: 0.9055 - val_loss: 0.4475\n",
      "Epoch 16/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9507 - loss: 0.1197 - val_accuracy: 0.8994 - val_loss: 0.4788\n",
      "Epoch 17/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9527 - loss: 0.1178 - val_accuracy: 0.9041 - val_loss: 0.4553\n",
      "Epoch 18/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9566 - loss: 0.1057 - val_accuracy: 0.8946 - val_loss: 0.5927\n",
      "Epoch 19/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9503 - loss: 0.1199 - val_accuracy: 0.9062 - val_loss: 0.5974\n",
      "Epoch 20/20\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9522 - loss: 0.1076 - val_accuracy: 0.8946 - val_loss: 0.5485\n",
      "\n",
      "CNN-LSTM Results:\n",
      "Accuracy:  0.9230\n",
      "Precision: 0.9233\n",
      "Recall:    0.9254\n",
      "F1-Score:  0.9237\n",
      "\n",
      "Detailed Classification Report for CNN-LSTM:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       1.00      0.95      0.98       496\n",
      "  WALKING_UPSTAIRS       0.92      0.95      0.93       471\n",
      "WALKING_DOWNSTAIRS       0.90      1.00      0.95       420\n",
      "           SITTING       0.85      0.85      0.85       491\n",
      "          STANDING       0.87      0.86      0.86       532\n",
      "            LAYING       1.00      0.95      0.97       537\n",
      "\n",
      "          accuracy                           0.92      2947\n",
      "         macro avg       0.92      0.93      0.92      2947\n",
      "      weighted avg       0.92      0.92      0.92      2947\n",
      "\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON TABLE\n",
      "UCI HAR Dataset - Raw Inertial Signals\n",
      "================================================================================\n",
      "   Model Accuracy Precision Recall F1-Score\n",
      "     MLP   0.9169    0.9184 0.9193   0.9172\n",
      "     CNN   0.9199    0.9217 0.9224   0.9205\n",
      "    LSTM   0.9084    0.9117 0.9098   0.9089\n",
      "CNN-LSTM   0.9230    0.9233 0.9254   0.9237\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MODEL ANALYSIS\n",
      "================================================================================\n",
      " Best Performance: CNN-LSTM\n",
      "   F1-Score: 0.9237\n",
      "   Accuracy: 0.9230\n",
      "\n",
      " Performance Ranking (by F1-Score):\n",
      "   1. CNN-LSTM: 0.9237\n",
      "   2. CNN: 0.9205\n",
      "   3. MLP: 0.9172\n",
      "   4. LSTM: 0.9089\n",
      "\n",
      " Model-Specific Insights:\n",
      "   • MLP (F1: 0.9172)\n",
      "     - Uses flattened raw signals (1152 features)\n",
      "     - Good baseline, loses temporal structure\n",
      "   • CNN (F1: 0.9205)\n",
      "     - Excels at local pattern detection\n",
      "     - Good for spatial/local temporal features\n",
      "   • LSTM (F1: 0.9089)\n",
      "     - Specializes in long-term temporal dependencies\n",
      "     - Good for sequence modeling\n",
      "   • CNN-LSTM (F1: 0.9237)\n",
      "     - Combines local patterns + sequence modeling\n",
      "     - Most sophisticated approach\n",
      "\n",
      " Key Findings:\n",
      "   • All models use RAW inertial signals (as required)\n",
      "   • Data shape: (samples, 128 timesteps, 9 sensors)\n",
      "   • 9 sensors: 3×acc + 3×gyro + 3×total_acc\n",
      "   • Performance difference: 0.0148\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "class UCIHARBenchmark:\n",
    "    def __init__(self, data_path):\n",
    "       \n",
    "        self.data_path = data_path\n",
    "        self.X_train_raw = None \n",
    "        self.X_test_raw = None   \n",
    "        self.X_train_flat = None \n",
    "        self.X_test_flat = None  \n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.n_classes = 6\n",
    "        self.n_timesteps = 128    \n",
    "        self.n_sensors = 9        \n",
    "        self.activity_labels = {\n",
    "            0: 'WALKING',\n",
    "            1: 'WALKING_UPSTAIRS', \n",
    "            2: 'WALKING_DOWNSTAIRS',\n",
    "            3: 'SITTING',\n",
    "            4: 'STANDING',\n",
    "            5: 'LAYING'\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def load_raw_signals(self):\n",
    "  \n",
    "        print(\"Loading UCI HAR Dataset - RAW INERTIAL SIGNALS...\")\n",
    "        \n",
    "        try:\n",
    "         \n",
    "            signal_files = [\n",
    "                'body_acc_x_train.txt', 'body_acc_y_train.txt', 'body_acc_z_train.txt',\n",
    "                'body_gyro_x_train.txt', 'body_gyro_y_train.txt', 'body_gyro_z_train.txt',\n",
    "                'total_acc_x_train.txt', 'total_acc_y_train.txt', 'total_acc_z_train.txt'\n",
    "            ]\n",
    "            \n",
    "            test_signal_files = [\n",
    "                'body_acc_x_test.txt', 'body_acc_y_test.txt', 'body_acc_z_test.txt',\n",
    "                'body_gyro_x_test.txt', 'body_gyro_y_test.txt', 'body_gyro_z_test.txt',\n",
    "                'total_acc_x_test.txt', 'total_acc_y_test.txt', 'total_acc_z_test.txt'\n",
    "            ]\n",
    "            \n",
    "\n",
    "            print(\"Loading training raw signals...\")\n",
    "            train_signals = []\n",
    "            for signal_file in signal_files:\n",
    "                signal_path = os.path.join(self.data_path, 'train', 'Inertial Signals', signal_file)\n",
    "                signal_data = np.loadtxt(signal_path)\n",
    "                train_signals.append(signal_data)\n",
    "            \n",
    "\n",
    "            self.X_train_raw = np.stack(train_signals, axis=2)\n",
    "            \n",
    "\n",
    "            print(\"Loading test raw signals...\")\n",
    "            test_signals = []\n",
    "            for signal_file in test_signal_files:\n",
    "                signal_path = os.path.join(self.data_path, 'test', 'Inertial Signals', signal_file)\n",
    "                signal_data = np.loadtxt(signal_path)\n",
    "                test_signals.append(signal_data)\n",
    "            \n",
    "\n",
    "            self.X_test_raw = np.stack(test_signals, axis=2)\n",
    "            \n",
    "\n",
    "            y_train_path = os.path.join(self.data_path, 'train', 'y_train.txt')\n",
    "            y_test_path = os.path.join(self.data_path, 'test', 'y_test.txt')\n",
    "            \n",
    "            self.y_train = np.loadtxt(y_train_path).astype(int) - 1  \n",
    "            self.y_test = np.loadtxt(y_test_path).astype(int) - 1   \n",
    "            \n",
    "\n",
    "            self.X_train_flat = self.X_train_raw.reshape(self.X_train_raw.shape[0], -1)\n",
    "            self.X_test_flat = self.X_test_raw.reshape(self.X_test_raw.shape[0], -1)\n",
    "            \n",
    "\n",
    "            self.X_train_flat = self.scaler.fit_transform(self.X_train_flat)\n",
    "            self.X_test_flat = self.scaler.transform(self.X_test_flat)\n",
    "            \n",
    "            print(f\" Raw signals loaded successfully:\")\n",
    "            print(f\"   Training raw: {self.X_train_raw.shape} (samples, timesteps, sensors)\")\n",
    "            print(f\"   Test raw: {self.X_test_raw.shape}\")\n",
    "            print(f\"   Training flat: {self.X_train_flat.shape} (for MLP)\")\n",
    "            print(f\"   Test flat: {self.X_test_flat.shape} (for MLP)\")\n",
    "            print(f\"   Labels: {self.y_train.shape} train, {self.y_test.shape} test\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading raw signals: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def build_mlp(self):\n",
    "      \n",
    "        print(\"Building MLP model...\")\n",
    "        print(\"Architecture: Input → Dense(512) → Dense(256) → Dense(128) → Output\")\n",
    "        \n",
    "        input_dim = self.X_train_flat.shape[1]  \n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(self.n_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(f\"MLP model built with {model.count_params():,} parameters\")\n",
    "        return model\n",
    "    \n",
    "    def build_cnn(self):\n",
    " \n",
    "        print(\"Building CNN model...\")\n",
    "        print(\"Architecture: Input → Conv1D → Conv1D → GlobalMaxPool → Dense → Output\")\n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(self.n_timesteps, self.n_sensors)),\n",
    "            layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "            layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
    "            layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.GlobalMaxPooling1D(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(self.n_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(f\"CNN model built with {model.count_params():,} parameters\")\n",
    "        return model\n",
    "    \n",
    "    def build_lstm(self):\n",
    "       \n",
    "        print(\"Building LSTM model...\")\n",
    "        print(\"Architecture: Input → LSTM(100) → LSTM(100) → Dense(50) → Output\")\n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(self.n_timesteps, self.n_sensors)),\n",
    "            layers.LSTM(100, return_sequences=True, dropout=0.3, recurrent_dropout=0.3),\n",
    "            layers.LSTM(100, dropout=0.3, recurrent_dropout=0.3),\n",
    "            layers.Dense(50, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(self.n_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(f\"LSTM model built with {model.count_params():,} parameters\")\n",
    "        return model\n",
    "    \n",
    "    def build_cnn_lstm(self):\n",
    "    \n",
    "        print(\"Building CNN-LSTM Hybrid model...\")\n",
    "        print(\"Architecture: Input → Conv1D → Conv1D → MaxPool → LSTM → LSTM → Dense → Output\")\n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(self.n_timesteps, self.n_sensors)),\n",
    "\n",
    "            layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "            layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "            layers.LSTM(50, return_sequences=True, dropout=0.3),\n",
    "            layers.LSTM(50, dropout=0.3),\n",
    "\n",
    "            layers.Dense(50, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(self.n_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(f\"CNN-LSTM model built with {model.count_params():,} parameters\")\n",
    "        return model\n",
    "    \n",
    "    def train_and_evaluate_model(self, model, model_name, use_raw_signals=True, epochs=30, batch_size=32):\n",
    "  \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "\n",
    "        if use_raw_signals:\n",
    "            X_train, X_test = self.X_train_raw, self.X_test_raw\n",
    "            print(f\"Using raw signals shape: {X_train.shape}\")\n",
    "        else:\n",
    "            X_train, X_test = self.X_train_flat, self.X_test_flat\n",
    "            print(f\"Using flattened signals shape: {X_train.shape}\")\n",
    "        \n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, self.y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "\n",
    "        y_pred = model.predict(X_test, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "\n",
    "        accuracy = accuracy_score(self.y_test, y_pred_classes)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            self.y_test, y_pred_classes, average='macro', zero_division=0\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.results[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{model_name} Results:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"F1-Score:  {f1:.4f}\")\n",
    "        \n",
    "\n",
    "        print(f\"\\nDetailed Classification Report for {model_name}:\")\n",
    "        target_names = [self.activity_labels[i] for i in range(self.n_classes)]\n",
    "        print(classification_report(self.y_test, y_pred_classes, target_names=target_names))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_results_table(self):\n",
    "\n",
    "        if not self.results:\n",
    "            print(\"No results available. Run models first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COMPREHENSIVE MODEL COMPARISON TABLE\")\n",
    "        print(\"UCI HAR Dataset - Raw Inertial Signals\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "\n",
    "        results_data = []\n",
    "        for model_name, metrics in self.results.items():\n",
    "            results_data.append({\n",
    "                'Model': model_name,\n",
    "                'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "                'Precision': f\"{metrics['precision']:.4f}\",\n",
    "                'Recall': f\"{metrics['recall']:.4f}\",\n",
    "                'F1-Score': f\"{metrics['f1_score']:.4f}\"\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results_data)\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def analyze_results(self):\n",
    "\n",
    "        if not self.results:\n",
    "            print(\"No results available. Run models first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COMPREHENSIVE MODEL ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "\n",
    "        best_model = max(self.results.items(), key=lambda x: x[1]['f1_score'])\n",
    "        worst_model = min(self.results.items(), key=lambda x: x[1]['f1_score'])\n",
    "        \n",
    "        print(f\" Best Performance: {best_model[0]}\")\n",
    "        print(f\"   F1-Score: {best_model[1]['f1_score']:.4f}\")\n",
    "        print(f\"   Accuracy: {best_model[1]['accuracy']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n Performance Ranking (by F1-Score):\")\n",
    "        sorted_results = sorted(self.results.items(), key=lambda x: x[1]['f1_score'], reverse=True)\n",
    "        for i, (model, metrics) in enumerate(sorted_results, 1):\n",
    "            print(f\"   {i}. {model}: {metrics['f1_score']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n Model-Specific Insights:\")\n",
    "        \n",
    "        if 'MLP' in self.results:\n",
    "            mlp_f1 = self.results['MLP']['f1_score']\n",
    "            print(f\"   • MLP (F1: {mlp_f1:.4f})\")\n",
    "            print(f\"     - Uses flattened raw signals (1152 features)\")\n",
    "            print(f\"     - Good baseline, loses temporal structure\")\n",
    "        \n",
    "        if 'CNN' in self.results:\n",
    "            cnn_f1 = self.results['CNN']['f1_score']\n",
    "            print(f\"   • CNN (F1: {cnn_f1:.4f})\")\n",
    "            print(f\"     - Excels at local pattern detection\")\n",
    "            print(f\"     - Good for spatial/local temporal features\")\n",
    "        \n",
    "        if 'LSTM' in self.results:\n",
    "            lstm_f1 = self.results['LSTM']['f1_score']\n",
    "            print(f\"   • LSTM (F1: {lstm_f1:.4f})\")\n",
    "            print(f\"     - Specializes in long-term temporal dependencies\")\n",
    "            print(f\"     - Good for sequence modeling\")\n",
    "        \n",
    "        if 'CNN-LSTM' in self.results:\n",
    "            cnn_lstm_f1 = self.results['CNN-LSTM']['f1_score']\n",
    "            print(f\"   • CNN-LSTM (F1: {cnn_lstm_f1:.4f})\")\n",
    "            print(f\"     - Combines local patterns + sequence modeling\")\n",
    "            print(f\"     - Most sophisticated approach\")\n",
    "        \n",
    "        print(f\"\\n Key Findings:\")\n",
    "        print(f\"   • All models use RAW inertial signals (as required)\")\n",
    "        print(f\"   • Data shape: (samples, 128 timesteps, 9 sensors)\")\n",
    "        print(f\"   • 9 sensors: 3×acc + 3×gyro + 3×total_acc\")\n",
    "        print(f\"   • Performance difference: {best_model[1]['f1_score'] - worst_model[1]['f1_score']:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_path = r\"/Users/advait/Desktop/Jupyter/ML-1/human/UCI_HAR_Dataset\"\n",
    "    \n",
    "\n",
    "    benchmark = UCIHARBenchmark(data_path)\n",
    "    \n",
    "\n",
    "    if benchmark.load_raw_signals():\n",
    "        print(\"\\n Starting comprehensive benchmarking with RAW signals...\")\n",
    "        \n",
    "\n",
    "        models_to_train = [\n",
    "            ('MLP', benchmark.build_mlp, False),       \n",
    "            ('CNN', benchmark.build_cnn, True),        \n",
    "            ('LSTM', benchmark.build_lstm, True),      \n",
    "            ('CNN-LSTM', benchmark.build_cnn_lstm, True)\n",
    "        ]\n",
    "        \n",
    "        for model_name, build_func, use_raw in models_to_train:\n",
    "            print(f\"\\n Training {model_name}...\")\n",
    "            model = build_func()\n",
    "            benchmark.train_and_evaluate_model(\n",
    "                model, model_name, \n",
    "                use_raw_signals=use_raw, \n",
    "                epochs=20, batch_size=32\n",
    "            )\n",
    "            \n",
    "\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "        \n",
    "\n",
    "        benchmark.create_results_table()\n",
    "        benchmark.analyze_results()\n",
    "        \n",
    "       \n",
    "        \n",
    "    else:\n",
    "        print(\"Not \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c8273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238590db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
